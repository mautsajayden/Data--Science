{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354f236a",
   "metadata": {},
   "source": [
    "Housing Prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53019f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DIR = os.path.dirname(__file__)\n",
    "\n",
    "#read the data \n",
    "X_full = pd.read_csv(os.path.join(BASE_DIR, \"train.csv\"),index_col='Id')\n",
    "X_test_full = pd.read_csv(os.path.join(BASE_DIR, \"test.csv\"),index_col='Id')\n",
    "\n",
    "#obtaining the features and the target predictiosn \n",
    "\n",
    "y = X_full.SalePrice\n",
    "\n",
    "features =  ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "\n",
    "X = X_full[features].copy()\n",
    "X_test = X_test_full[features].copy()\n",
    "\n",
    "#break off validation set from training data\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061125e",
   "metadata": {},
   "source": [
    "Looking at the first 5 rows of the data to use for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb16929",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a7ab3",
   "metadata": {},
   "source": [
    "Making the Forest tree model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c75f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#define the models \n",
    "\n",
    "model1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model2 = RandomForestRegressor(n_estimators=100, random_state= 0)\n",
    "model3 = RandomForestRegressor(n_estimators= 100, criterion='absolute_error',random_state=0)\n",
    "model4 = RandomForestRegressor(n_estimators=200, min_samples_split=20,random_state= 0 )\n",
    "model5 = RandomForestRegressor(n_estimators= 100, max_depth=7, random_state=0)\n",
    "\n",
    "#list with models \n",
    "models = [model1,model2,model3,model4,model5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2116a02",
   "metadata": {},
   "source": [
    "Checking the model with the lowest MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics  import mean_absolute_error\n",
    "\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t,y_t)\n",
    "    predictions = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v,predictions)    \n",
    "\n",
    "score_mae = []\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    score_mae.append(mae)\n",
    "    print(f\"Model: {i+1} MAE: {mae}\")\n",
    "    \n",
    "#the best model\n",
    "min_mae = min(score_mae)\n",
    "best_model = [ x  for x in range(len(score_mae)) if score_mae[x] == min_mae ]\n",
    " \n",
    "print(f'The best model: {best_model[0]+1} , MAE = {min_mae} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60ac26",
   "metadata": {},
   "source": [
    "Using the lowest MAE Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = models[best_model[0]+1]\n",
    "\n",
    "myModel.fit(X,y)\n",
    "\n",
    "preds = myModel.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ab98a",
   "metadata": {},
   "source": [
    "Fixing missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e880a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "\n",
    "#comparing different estimations \n",
    "\n",
    "def score_dataset(X_train,X_valid,y_train,y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10,random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_valid)\n",
    "    mae = mean_absolute_error(y_valid,predictions)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fa7bf",
   "metadata": {},
   "source": [
    "Dropping missing all NA columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with missing values \n",
    "\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "#dropping the missing columsn in the test and training data \n",
    "reduced_X_train = X_train.drop(cols_with_missing,axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing,axis=1)\n",
    "\n",
    "print(score_dataset(reduced_X_train,reduced_X_valid, y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17b604",
   "metadata": {},
   "source": [
    "Fixing missing values by using imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71724b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputation \n",
    "\n",
    "my_imputer = SimpleImputer\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print('MAE : ', score_dataset(imputed_X_train,imputed_X_valid,y_train,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb71cc1",
   "metadata": {},
   "source": [
    "Fixing the missing values using extension of imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdff195",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "    \n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print('MAE: ',score_dataset(imputed_X_train_plus,imputed_X_valid_plus,y_train,y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
